{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed54e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1094868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 Naive Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "85e56103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Term       Sales  Naive_Forecast  Percent_Abs_Diff\n",
      "0  2015-01-01 1,450,955.0             NaN               NaN\n",
      "1  2015-02-01 1,869,343.0     1,450,955.0              22.4\n",
      "2  2015-03-01 1,475,322.0     1,869,343.0              26.7\n",
      "3  2015-04-01 2,988,343.0     1,475,322.0              50.6\n",
      "4  2015-05-01 3,900,344.0     2,988,343.0              23.4\n",
      "5  2015-06-01 1,546,435.0     3,900,344.0             152.2\n",
      "6  2015-07-01 1,858,355.0     1,546,435.0              16.8\n",
      "7  2015-08-01 4,349,222.0     1,858,355.0              57.3\n",
      "8  2015-09-01 4,100,343.0     4,349,222.0               6.1\n",
      "9  2015-10-01 3,844,355.0     4,100,343.0               6.7\n",
      "10 2015-11-01 3,800,111.0     3,844,355.0               1.2\n",
      "11 2015-12-01 6,324,967.0     3,800,111.0              39.9\n",
      "12 2016-01-01 4,023,453.0     6,324,967.0              57.2\n",
      "13 2016-02-01 4,030,000.0     4,023,453.0               0.2\n",
      "14 2016-03-01 3,988,453.0     4,030,000.0               1.0\n",
      "15 2016-04-01 5,034,000.0     3,988,453.0              20.8\n",
      "16 2016-05-01 5,335,210.0     5,034,000.0               5.6\n",
      "17 2016-06-01 3,632,435.0     5,335,210.0              46.9\n",
      "18 2016-07-01 4,000,100.0     3,632,435.0               9.2\n",
      "19 2016-08-01 6,100,100.0     4,000,100.0              34.4\n",
      "20 2016-09-01 5,867,347.0     6,100,100.0               4.0\n",
      "21 2016-10-01 5,500,010.0     5,867,347.0               6.7\n",
      "22 2016-11-01 6,003,000.0     5,500,010.0               8.4\n",
      "23 2016-12-01 9,100,887.0     6,003,000.0              34.0\n",
      "24 2017-01-01 5,500,333.0     9,100,887.0              65.5\n",
      "25 2017-02-01 6,000,000.0     5,500,333.0               8.3\n",
      "26 2017-03-01 6,500,343.0     6,000,000.0               7.7\n",
      "27 2017-04-01 6,886,300.0     6,500,343.0               5.6\n",
      "28 2017-05-01 7,109,533.0     6,886,300.0               3.1\n",
      "29 2017-06-01 5,333,454.0     7,109,533.0              33.3\n"
     ]
    }
   ],
   "source": [
    "# Input data\n",
    "data = {\n",
    "    'Term': ['2015 Jan', '2015 Feb', '2015 Mar', '2015 Apr', '2015 May', '2015 Jun', '2015 Jul', '2015 Aug', '2015 Sep', '2015 Oct', '2015 Nov', '2015 Dec', '2016 Jan', '2016 Feb', '2016 Mar', '2016 Apr', '2016 May', '2016 Jun', '2016 Jul', '2016 Aug', '2016 Sep', '2016 Oct', '2016 Nov', '2016 Dec', '2017 Jan', '2017 Feb', '2017 Mar', '2017 Apr', '2017 May', '2017 Jun', '2017 Jul'],\n",
    "    'Sales': [1450955, 1869343, 1475322, 2988343, 3900344, 1546435, 1858355, 4349222, 4100343, 3844355, 3800111, 6324967, 4023453, 4030000, 3988453, 5034000, 5335210, 3632435, 4000100, 6100100, 5867347, 5500010, 6003000, 9100887, 5500333, 6000000, 6500343, 6886300, 7109533, 5333454, None]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop rows with missing data in the 'Sales' column\n",
    "df = df.dropna(subset=['Sales'])\n",
    "\n",
    "# Convert the 'Term' column to datetime with the updated format\n",
    "df['Term'] = pd.to_datetime(df['Term'] + ' 01', format='%Y %b %d')\n",
    "\n",
    "# Perform the Naive forecasting\n",
    "df['Naive_Forecast'] = df['Sales'].shift()\n",
    "\n",
    "# Calculate the percent absolute difference\n",
    "df['Percent_Abs_Diff'] = (abs(df['Sales'] - df['Naive_Forecast']) / df['Sales']) * 100\n",
    "\n",
    "# Round the 'Percent_Abs_Diff' column to 1 decimal place\n",
    "df['Percent_Abs_Diff'] = df['Percent_Abs_Diff'].round(1)\n",
    "\n",
    "# Display the forecast and percent absolute difference\n",
    "print(df[['Term', 'Sales', 'Naive_Forecast', 'Percent_Abs_Diff']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "396fbecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 Simple Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2461487e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Term       Sales  Moving_Average_Forecast\n",
      "0  2015-01-01 1,450,955.0                      NaN\n",
      "1  2015-02-01 1,869,343.0                      NaN\n",
      "2  2015-03-01 1,475,322.0              1,598,540.0\n",
      "3  2015-04-01 2,988,343.0              2,111,002.7\n",
      "4  2015-05-01 3,900,344.0              2,788,003.0\n",
      "5  2015-06-01 1,546,435.0              2,811,707.3\n",
      "6  2015-07-01 1,858,355.0              2,435,044.7\n",
      "7  2015-08-01 4,349,222.0              2,584,670.7\n",
      "8  2015-09-01 4,100,343.0              3,435,973.3\n",
      "9  2015-10-01 3,844,355.0              4,097,973.3\n",
      "10 2015-11-01 3,800,111.0              3,914,936.3\n",
      "11 2015-12-01 6,324,967.0              4,656,477.7\n",
      "12 2016-01-01 4,023,453.0              4,716,177.0\n",
      "13 2016-02-01 4,030,000.0              4,792,806.7\n",
      "14 2016-03-01 3,988,453.0              4,013,968.7\n",
      "15 2016-04-01 5,034,000.0              4,350,817.7\n",
      "16 2016-05-01 5,335,210.0              4,785,887.7\n",
      "17 2016-06-01 3,632,435.0              4,667,215.0\n",
      "18 2016-07-01 4,000,100.0              4,322,581.7\n",
      "19 2016-08-01 6,100,100.0              4,577,545.0\n",
      "20 2016-09-01 5,867,347.0              5,322,515.7\n",
      "21 2016-10-01 5,500,010.0              5,822,485.7\n",
      "22 2016-11-01 6,003,000.0              5,790,119.0\n",
      "23 2016-12-01 9,100,887.0              6,867,965.7\n",
      "24 2017-01-01 5,500,333.0              6,868,073.3\n",
      "25 2017-02-01 6,000,000.0              6,867,073.3\n",
      "26 2017-03-01 6,500,343.0              6,000,225.3\n",
      "27 2017-04-01 6,886,300.0              6,462,214.3\n",
      "28 2017-05-01 7,109,533.0              6,832,058.7\n",
      "29 2017-06-01 5,333,454.0              6,443,095.7\n"
     ]
    }
   ],
   "source": [
    "# Perform the Moving Average forecasting (using a window size of 3 for example)\n",
    "window_size = 3\n",
    "df['Moving_Average_Forecast'] = df['Sales'].rolling(window=window_size).mean()\n",
    "\n",
    "# Round the 'Moving_Average_Forecast' column to 1 decimal place\n",
    "df['Moving_Average_Forecast'] = df['Moving_Average_Forecast'].round(1)\n",
    "\n",
    "# Display the forecast based on moving average\n",
    "print(df[['Term', 'Sales', 'Moving_Average_Forecast']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9316d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3 Weighted Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8c2ee196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Term       Sales  Weighted_Average_Forecast\n",
      "0  2015-01-01 1,450,955.0                        NaN\n",
      "1  2015-02-01 1,869,343.0                        NaN\n",
      "2  2015-03-01 1,475,322.0                1,588,654.9\n",
      "3  2015-04-01 2,988,343.0                2,310,636.7\n",
      "4  2015-05-01 3,900,344.0                3,141,739.3\n",
      "5  2015-06-01 1,546,435.0                2,540,989.3\n",
      "6  2015-07-01 1,858,355.0                2,173,176.8\n",
      "7  2015-08-01 4,349,222.0                3,041,404.5\n",
      "8  2015-09-01 4,100,343.0                3,726,609.1\n",
      "9  2015-10-01 3,844,355.0                4,022,124.8\n",
      "10 2015-11-01 3,800,111.0                3,873,430.6\n",
      "11 2015-12-01 6,324,967.0                5,071,387.8\n",
      "12 2016-01-01 4,023,453.0                4,669,238.8\n",
      "13 2016-02-01 4,030,000.0                4,487,029.3\n",
      "14 2016-03-01 3,988,453.0                4,007,917.1\n",
      "15 2016-04-01 5,034,000.0                4,519,535.9\n",
      "16 2016-05-01 5,335,210.0                4,975,495.6\n",
      "17 2016-06-01 3,632,435.0                4,423,580.5\n",
      "18 2016-07-01 4,000,100.0                4,156,822.5\n",
      "19 2016-08-01 6,100,100.0                4,976,567.0\n",
      "20 2016-09-01 5,867,347.0                5,563,723.5\n",
      "21 2016-10-01 5,500,010.0                5,730,229.1\n",
      "22 2016-11-01 6,003,000.0                5,824,972.4\n",
      "23 2016-12-01 9,100,887.0                7,451,345.5\n",
      "24 2017-01-01 5,500,333.0                6,681,032.6\n",
      "25 2017-02-01 6,000,000.0                6,470,277.3\n",
      "26 2017-03-01 6,500,343.0                6,150,238.1\n",
      "27 2017-04-01 6,886,300.0                6,593,252.9\n",
      "28 2017-05-01 7,109,533.0                6,920,725.1\n",
      "29 2017-06-01 5,333,454.0                6,176,846.9\n"
     ]
    }
   ],
   "source": [
    "# Calculate the 3-month weighted average\n",
    "window_size = 3\n",
    "weights = [0.2, 0.3, 0.5]  # Assigning weights to the months (most recent to least recent)\n",
    "df['Weighted_Average_Forecast'] = df['Sales'].rolling(window=window_size).apply(lambda x: (x * weights).sum(), raw=True)\n",
    "\n",
    "# Round the 'Weighted_Average_Forecast' column to 1 decimal place\n",
    "df['Weighted_Average_Forecast'] = df['Weighted_Average_Forecast'].round(1)\n",
    "\n",
    "# Display the forecast based on the 3-month weighted average\n",
    "print(df[['Term', 'Sales', 'Weighted_Average_Forecast']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ea811d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.4 Season Adjusted Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cf43988a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Sales  Deseasonalized_Sales      Trend  Seasonal_Adjusted_Trend  \\\n",
      "Quarter                                                                       \n",
      "2015Q1    4795620             5671548.4  9062262.4                7656260.8   \n",
      "2015Q2    8435122             8057159.5  9062262.4                9178768.9   \n",
      "2015Q3   10307920            10490352.6  9062262.4                8661691.1   \n",
      "2015Q4   13969433            11079413.1  9062262.4               11397076.3   \n",
      "2016Q1   12041906            14276593.8 14916066.0               12601852.2   \n",
      "2016Q2   14001645            13877366.5 14916066.0               15107830.3   \n",
      "2016Q3   15967547            17000258.0 14916066.0               14256744.2   \n",
      "2016Q4   20603897            16411197.5 14916066.0               18759062.1   \n",
      "2017Q1   18000676            21287773.7 20769869.7               17547443.8   \n",
      "2017Q2   19329287            19301389.9 20769869.7               21036891.8   \n",
      "\n",
      "         Seasonal_Index  \n",
      "Quarter                  \n",
      "2015Q1              0.9  \n",
      "2015Q2              1.0  \n",
      "2015Q3              0.9  \n",
      "2015Q4              1.3  \n",
      "2016Q1              0.9  \n",
      "2016Q2              1.0  \n",
      "2016Q3              0.9  \n",
      "2016Q4              1.3  \n",
      "2017Q1              0.9  \n",
      "2017Q2              1.0  \n"
     ]
    }
   ],
   "source": [
    "# Extract quarter, month, and year from the 'Term' column\n",
    "df['Quarter'] = df['Term'].dt.to_period('Q')\n",
    "df['Month'] = df['Term'].dt.month\n",
    "df['Year'] = df['Term'].dt.year\n",
    "\n",
    "# Calculate the seasonal indices\n",
    "seasonal_index = df.groupby('Month')['Sales'].mean() / df['Sales'].mean()\n",
    "\n",
    "# Calculate the deseasonalized values\n",
    "df['Seasonal_Index'] = df['Month'].map(seasonal_index)\n",
    "df['Deseasonalized_Sales'] = df['Sales'] / df['Seasonal_Index']\n",
    "\n",
    "# Perform linear regression to find the trend component\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(df[['Year']], df['Deseasonalized_Sales'])\n",
    "df['Trend'] = regression_model.predict(df[['Year']])\n",
    "\n",
    "# Calculate the seasonal adjusted trend\n",
    "df['Seasonal_Adjusted_Trend'] = df['Trend'] * df['Seasonal_Index']\n",
    "\n",
    "# Round the 'Seasonal_Adjusted_Trend' and 'Seasonal_Index' columns to 1 decimal place\n",
    "df['Seasonal_Adjusted_Trend'] = df['Seasonal_Adjusted_Trend'].round(1)\n",
    "df['Seasonal_Index'] = df['Seasonal_Index'].round(1)\n",
    "\n",
    "# Group by quarter and aggregate the values\n",
    "quarterly_df = df.groupby('Quarter').agg(\n",
    "    Sales=('Sales', 'sum'),\n",
    "    Deseasonalized_Sales=('Deseasonalized_Sales', 'sum'),\n",
    "    Trend=('Trend', 'sum'),\n",
    "    Seasonal_Adjusted_Trend=('Seasonal_Adjusted_Trend', 'sum'),\n",
    "    Seasonal_Index=('Seasonal_Index', 'mean')\n",
    ")\n",
    "\n",
    "# Display the results in a standard format with no scientific notation\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "print(quarterly_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "04ccd6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.5 Simple Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ab95d780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Sales  Smoothed_Sales_0.9  Smoothed_Sales_0.5  Smoothed_Sales_0.3\n",
      "Term                                                                        \n",
      "2015Q1   4795620                 NaN                 NaN                 NaN\n",
      "2015Q2   8435122        4,795,620.00        4,795,620.00        4,795,620.00\n",
      "2015Q3  10307920        9,756,690.00        7,551,770.00        6,449,310.00\n",
      "2015Q4  13969433       13,548,158.70       10,760,601.50        8,705,346.90\n",
      "2016Q1  12041906       12,192,531.27       11,401,253.75        9,706,314.63\n",
      "2016Q2  14001645       13,820,733.63       12,701,449.38       10,994,913.74\n",
      "2016Q3  15967547       15,752,865.66       14,334,498.19       12,486,703.72\n",
      "2016Q4  20603897       20,118,793.87       17,469,197.59       14,921,861.70\n",
      "2017Q1  18000676       18,212,487.79       17,734,936.80       15,845,505.99\n",
      "2017Q2  19329287       19,217,607.08       18,532,111.90       16,890,640.29\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Input data\n",
    "data = {\n",
    "    'Term': ['2015Q1', '2015Q2', '2015Q3', '2015Q4', '2016Q1', '2016Q2', '2016Q3', '2016Q4', '2017Q1', '2017Q2'],\n",
    "    'Sales': [4795620, 8435122, 10307920, 13969433, 12041906, 14001645, 15967547, 20603897, 18000676, 19329287],\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the 'Term' column to datetime\n",
    "df['Term'] = pd.to_datetime(df['Term'])\n",
    "\n",
    "# Set the smoothing parameters\n",
    "alphas = [0.9, 0.5, 0.3]\n",
    "\n",
    "# Initialize the first smoothed value for 2015Q2 using 2015Q1 sales for each alpha\n",
    "for alpha in alphas:\n",
    "    df.loc[df['Term'] == '2015Q2', f'Smoothed_Sales_{alpha}'] = df.loc[df['Term'] == '2015Q1', 'Sales'].values[0]\n",
    "\n",
    "# Perform simple exponential smoothing for the remaining observations\n",
    "for i in range(df[df['Term'] == '2015Q2'].index[0] + 1, len(df)):\n",
    "    for alpha in alphas:\n",
    "        df.loc[i, f'Smoothed_Sales_{alpha}'] = alpha * df.loc[i, 'Sales'] + (1 - alpha) * df.loc[i - 1, f'Smoothed_Sales_{alpha}']\n",
    "\n",
    "# Group by quarter and aggregate the values\n",
    "quarterly_df = df.groupby(df['Term'].dt.to_period('Q')).agg(\n",
    "    Sales=('Sales', 'sum'),\n",
    "    **{f'Smoothed_Sales_{alpha}': (f'Smoothed_Sales_{alpha}', 'last') for alpha in alphas}\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "print(quarterly_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac7dc1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.4 Projecting Cash Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8cce947c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      EBIT  EBIAT  Depreciation  CAPEX  Delta for NWC  FCF\n",
      "2017   0.5    0.4           0.1    3.5           -2.1 -1.1\n",
      "2018   0.3    0.2           0.6    1.3           -2.0  0.4\n",
      "2019   0.4    0.3           0.8    2.4           -3.7  0.8\n",
      "2020   0.5    0.3           1.1    4.4           -7.0  1.9\n"
     ]
    }
   ],
   "source": [
    "# Input data - Income Statement\n",
    "income_data = {\n",
    "    '2017': [1.20, 0.53, 1.14, 0.06, 0.02, 0.05, 0.04, 0.11, 0.14, 0.25],\n",
    "    '2018': [1.80, 0.79, 1.01, 0.09, 0.04, 0.55, 0.05, 0.09, 0.06, 0.12],\n",
    "    '2019': [2.70, 1.19, 1.51, 0.14, 0.05, 0.80, 0.08, 0.07, 0.13, 0.24],\n",
    "    '2020': [3.38, 1.49, 1.89, 0.17, 0.07, 1.05, 0.10, 0.06, 0.16, 0.29]\n",
    "}\n",
    "\n",
    "# Input data - Balance Sheet\n",
    "balance_data = {\n",
    "    '2017': [1.28, 0.55, 0.01, 2.00, 1.50, -1.56, 3.78, 0.04, 0.13, 0.14, 0.07, 1.20, 1.08, 3.10, 0.63, 0.05, 0.68, 3.78],\n",
    "    '2018': [0.56, 0.18, 0.03, 0.00, 4.80, -2.11, 3.46, 0.06, 0.20, 0.06, 0.07, 0.75, 1.08, 2.67, 0.63, 0.16, 0.79, 3.46],\n",
    "    '2019': [3.50, 0.27, 0.05, 0.00, 7.20, -2.91, 8.11, 0.10, 0.29, 0.13, 0.07, 0.29, 5.76, 7.10, 0.63, 0.38, 1.01, 8.11],\n",
    "    '2020': [3.52, 0.34, 0.06, 0.00, 11.60, -3.96, 11.57, 0.12, 0.37, 0.16, 0.07, -0.17, 9.28, 10.30, 0.63, 0.64, 1.27, 11.57]\n",
    "}\n",
    "\n",
    "# Create DataFrames from the input data\n",
    "income_df = pd.DataFrame(income_data, index=['Net Sales', 'COGS', 'Gross Profit', 'Advertising', 'Office Expense',\n",
    "                                              'Depreciation', 'Repairs & Maintenance', 'Interest expense',\n",
    "                                              'Income Tax expense', 'Net Income'])\n",
    "\n",
    "balance_df = pd.DataFrame(balance_data, index=['Cash', 'Accounts Receivable', 'Inventory', 'Building', 'Equipment',\n",
    "                                                'Accumulated Depreciation', 'Total Assets', 'Accounts Payable',\n",
    "                                                'Wages Payable', 'Taxes Payable', 'Notes, short-term',\n",
    "                                                'Current Part, long-term debt', 'Other Long-Term Debt',\n",
    "                                                'Total Liabilities', 'Common Stock', 'Retained earnings',\n",
    "                                                'Total Equity', 'Total Liabilities and Equity'])\n",
    "\n",
    "# Calculate EBIT (Earnings Before Interest and Taxes)\n",
    "EBIT = income_df.loc['Net Income'] + income_df.loc['Interest expense'] + income_df.loc['Income Tax expense']\n",
    "\n",
    "# Calculate EBIAT (Earnings Before Interest, After Taxes)\n",
    "EBIAT = income_df.loc['Net Income'] + income_df.loc['Interest expense']\n",
    "\n",
    "# Calculate Depreciation\n",
    "Depreciation = income_df.loc['Depreciation']\n",
    "\n",
    "# Calculate CAPEX (Capital Expenditure)\n",
    "CAPEX = balance_df.loc['Building'].diff().fillna(balance_df.loc['Building'])\n",
    "CAPEX += balance_df.loc['Equipment'].diff().fillna(balance_df.loc['Equipment'])\n",
    "\n",
    "# Calculate the delta for NWC (Net Working Capital)\n",
    "delta_NWC = (balance_df.loc['Cash'] - balance_df.loc['Accounts Payable'] - balance_df.loc['Wages Payable'] -\n",
    "             balance_df.loc['Taxes Payable'] - balance_df.loc['Notes, short-term'] -\n",
    "             balance_df.loc['Current Part, long-term debt'] - balance_df.loc['Other Long-Term Debt'] -\n",
    "             balance_df.loc['Accounts Receivable'] - balance_df.loc['Inventory'] -\n",
    "             income_df.loc['Advertising'] - income_df.loc['Office Expense'] -\n",
    "             income_df.loc['Repairs & Maintenance'])\n",
    "\n",
    "# Calculate FCF (Free Cash Flow)\n",
    "FCF = EBIAT - Depreciation - CAPEX - delta_NWC\n",
    "\n",
    "# Create a table with the column headers as the years\n",
    "output_table = pd.DataFrame({'EBIT': EBIT,\n",
    "                             'EBIAT': EBIAT,\n",
    "                             'Depreciation': Depreciation,\n",
    "                             'CAPEX': CAPEX,\n",
    "                             'Delta for NWC': delta_NWC,\n",
    "                             'FCF': FCF})\n",
    "\n",
    "# Print the table\n",
    "print(output_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c435f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
